import { BlogPostLayout } from '@/components/BlogPostLayout'
import Image from 'next/image'

export const post = {
  draft: false,
  author: 'RÃ¼diger Klaehn',
  date: '2024-07-26',
  title: 'How iroh uses rust async',
  description:
    'Documenting some lessons we learned while writing iroh using rust async',
}

export const metadata = {
  title: post.title,
  description: post.description,
}

export default (props) => <BlogPostLayout article={post} {...props} />

# What is iroh

Regular readers of this blog already know this, but just to recap:

Iroh is a set of rust crates for p2p networking and data transfer. These can be
used using the [iroh binary](https://crates.io/crates/iroh-cli), any of the
various [ffi bindings](https://github.com/n0-computer/iroh-ffi), or the main
iroh crate or the individual parts can be used directly from other rust programs.

# Platforms

Iroh is supported on all major platforms including mobile. It works very diverse
hardware from raspberry pis to android or ios mobile phones, to beefy multicore
servers in the cloud.

# Why use async in the first place?

In many cases, especially for rust beginners, I encourage them to stay away from
async until they have mastered the language. And even once you have mastered the
language, there are a lot of pitfalls in async rust. So I stay away from async
rust whenever possible for personal fun projects.

But for iroh-net we are building on [quinn], an open source rust QUIC
implementation that has a very pleasant async API. For iroh-blobs we need to
handle frequent concurrent interactions with the blob store.

So we did not have much choice. We have to use async.

# Runtime choice

[Tokio] is the most popular async runtime, and also the only one that works on
all platforms and is well maintained. It is also the default runtime for quinn.
Since iroh is mostly about networking, we chose to use the tokio runtime.

# Interacting with blocking code

We are using [redb], a rust embedded database.

Redb, like [sqlite] and most other embedded databases, is fully synchronous. It
performs blocking IO in most calls. So using it directly in a tokio task is
*highly* discouraged.

Redb also allows only a single write transaction to be open at the same time. So
naive use would simply open a new write transaction on every update. But the
resulting performance would be absolutely horrible for demanding use cases,
and our blob store is a *very* demanding use case.

## Worker thread for IO

A very common pattern is to interact with a redb database via a std handler
thread that you interact with using message passing.

This is a pattern we have used in both the iroh blobs store and the iroh docs
store. It is also a very useful pattern to add an async facade to a complex
synchronous program.

For interaction between async an sync code, you need a mpsc or mpmc channel
that has both a pleasant sync API and a pleasant async API. Until recently,
[flume] was our preferred crate for this. It is a mpmc queue that offers a
pleasant async API including sink and stream wrappers for sender and receiver,
as well as a pleasant sync api including sending and receiving with timeout.

## Single threaded runtime for IO

An alternative that we have recently implemented in iroh documents is to do
blocking sync IO inside a thread that hosts a single threaded tokio runtime.
Blocking IO will of course stop all tasks on this runtime, but it will not have
any effect on the main runtime. You will be able to use lightweight tasks
in this runtime, which simplifies having several concurrent db (read) operations
like long lived iterators/streams.

## File IO

In addition to interacting with an embedded database, file io is a very
important part of the blob store. It inlines small blobs in redb, but uses the
file system for larger blobs. And a key distinguishing feature of iroh blobs
compared to other content-addressed storage systems like IPFS is the ability to
handle blobs of arbitrary size up to terabytes.

When sending or receiving data, work switches between waiting for the network
and performing file system io. Due to the fact that many embedded databases are
not `Send`, and we want to use the embedded database to inline small blocks, io
in iroh has to happen on non-`Send` tasks.
(I might expand on this in a subsequent post)

So we use a separate thread pool to spawn worker threads on for bulk
interactions with the blobs database.

# Problems

We have had several sets of problems when using async rust to implement iroh.
Here are some common issues we have ran into, and how we have mitigated them.

## Tokio panics

In normal rust code, you can usually understand how to safely use an API just
by looking at the types.

A very well designed API will make it *impossible* to use entities in an incorrect state because the different states the entities can be in are modeled in the type system. This follows a design principle called [make invalid states unrepesentable](https://geeklaunch.io/blog/make-invalid-states-unrepresentable/), and emerges naturally if you do the work to model your stateful entities as state machines.

Normal rust APIs such as the ones in std::io will have functions return an error if you call them when the entity is in the wrong state. When you call a function that does not return a Result, you can safely call it without having to worry about panics.

And then there is tokio.

In tokio, you *have* to read the docs to figure out when it is safe to call a function. The function signature itself does not provide any guarantees. Whether a function panics depends not just on the state of entities, but on global or rather thread-local state such as the ambient runtime or local set.

Various functions such as tokio::spawn panic if you call them *outside* a tokio runtime. Some other functions such as send_blocking helpfully panic if you call them from *inside* a tokio runtime.

But it does not end there. When working with local (non-Send) tasks things get even more complex. spawn_local panics when you are not "inside a LocalSet". Being inside a local set is inherited from the parent task when you are inside a task that was spawned via spawn_local, but not if you are inside a task that was spawned via spawn.

So in summary, to use local tasks you have to have a mental model of how the thread local variables underlying the global tokio functions spawn, spawn_local and spawn_blocking work. A simple error like spawning a local task using spawn instead of spawn_local can lead to a panic in a completely different part of the code base.

The ergonomics of tokio tasks for non-trivial use cases is... not great. And the ergonomics for non-`Send` tasks is even worse.

## Drop

Now, you could argue that you will not have these issues if you just stay within the tokio runtime all the time. But for a complex program that has to interact with blocking io this is not practical. Neither is it practical for a library crate that your users might use from many different contexts.

For example, you have an entity that contains an external resource such as a database or file, and want to cleanly close the resource on `Drop`. If this involves any interaction with the tokio runtime, such as sending a shutdown message: good luck.

You can not use [send](https://docs.rs/tokio/latest/tokio/sync/mpsc/struct.Sender.html#method.send) because Drop is not async. But you can also not use [blocking_send](https://docs.rs/tokio/latest/tokio/sync/mpsc/struct.Sender.html#method.blocking_send) because it will panic when used within a tokio runtime.

So if you want to do anything non trivial, such as sending messages, in Drop, you need to use a queue that allows blocking send both inside and outside the tokio runtime, such as [flume] or [async_channel]. Or use a queue that allows force sending a message without blocking in all cases, such as [force_send](https://docs.rs/async-channel/latest/async_channel/struct.Sender.html#method.force_send) in async channel.

There is also a third option: using an unbounded queue. Sending on an unbounded queue is non-blocking, so for the case of sending a message on drop this is great. But within the normal operation of your program, you now have to either live with the lack of backpressure and possible OOM error for that unbounded queue, or limit the size of the queue in some other way. The latter is doable, but adds a lot of complexity.

You could also just give up on one of the things that makes sync rust so nice,
resource acquisition is initialization [RAII](https://doc.rust-lang.org/rust-by-example/scope/raii.html)
and require the user to manually call `close().await` on each resource.

## Swallowing panics

Rust has a very powerful and ergonomic mechanism to handle results. So every well written rust API will at a minimum return results for every function that can fail. When quickly writing prototypes, you will use a crate like [anyhow] to handle these results. When writing production library code, you might spend the effort to use a crate like [thiserror] to write custom error types. So rust has the tools to ergonomically handle errors in both cases.

A panic on the other hand indicates that something serious has gone wrong. At the very minimum you want to prominently log a panic, but in almost all cases the best course of action is gather as much information as possible about the panic and then shut down the entire process.

Unfortunately, tokio makes it very easy to swallow panics.

When a panic happens in a tokio task, it will be captured by the tokio runtime and converted into a tokio [JoinError](https://docs.rs/tokio/latest/tokio/task/struct.JoinError.html). What you get back from spawn is a [JoinHandle] that
can be awaited to get that join error and possibly re-emit or at least log the panic. But it is very easy and in fact encouraged to just drop the JoinHandle and run the task detached, in which case a panic will just be silently swallowed.

## Complex combinators in futures are buggy

We have noticed that some complex combinators such as [FuturesUnordered] in the
futures crate are buggy. Unfortunately the code uses a lot of unsafe, so fixing
it ourselves was not a realistic option.

We have therefore decided to take the drastic step to stop using the futures
crate altogehter and use a set of crates to replace it:
[futures-lite](https://crates.io/crates/futures-lite) for simple futures
and streams combinators.
[futures-buffered](https://crates.io/crates/futures-buffered) to replace FuturesUnordered
[futures-util] from the futures repo for the rare case where we want to use something
from futures that is not covered by either futures-lite or futures-buffered.

This makes working with async code even more unpleasant than it already is
because even writing simple code involves searching for a crate that has the
required combinator or type in our set of safe crates.


https://github.com/n0-computer/iroh/issues/1646

- futures buffered
- send from drop
- cancel safe send
- cancel safe recv
- select!
- LocalPoolHandle drop